<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>vtk-dicom: Character Sets</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">vtk-dicom
   &#160;<span id="projectnumber">0.8.13</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Character Sets </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Decoding and Encoding of Character Sets</p>
<h1><a class="anchor" id="autotoc_md7"></a>
Overview</h1>
<p>Even though it would be convenient for all DICOM files to store text in UTF-8, or even ASCII, the reality is that legacy character encodings are very common. Also, it is not uncommon to find DICOM files where the encoding does not conform perfectly with the standard. As a general rule, we want to be forgiving when decoding text in DICOM files, but we want to conform strictly to the standard when encoding text.</p>
<h1><a class="anchor" id="autotoc_md8"></a>
ASCII and ISO-8859</h1>
<p>Many of the ISO-8859 character sets are supported (and extended) by Microsoft code pages, and have become closely associated with those code pages. The most important of these is CP1252 (Windows-1252) which extends ISO-8859-1 (ISO IR 100). This code page replaces C1 control codes, which are unused by the ISO-8859 character sets, with commonly-used characters such the Euro sign, combined OE and oe, and left and right quotes (single and double).</p>
<h2><a class="anchor" id="autotoc_md9"></a>
Decoding</h2>
<p>Our decoder supports the decoding of these extra code points when the character set is ISO IR 100. The rationale is that CP1252 is fully backwards-compatible with ISO IR 100, and the C1 control codes are not used by DICOM. This same rule is applied for ISO IR 148 (via CP1254) and ISO IR 166 (via CP874). ISO IR 6, however, is decoded strictly as ASCII.</p>
<h2><a class="anchor" id="autotoc_md10"></a>
Encoding</h2>
<p>The extra characters that are supported by the decoder cannot also be supported by the encoder, since that would create files that do not conform with the DICOM standard. Instead, the encoder will convert the extra characters to ASCII code points in cases where there is a suitable replacment.</p>
<p>The conversions that the encoder uses are as follows:</p>
<ol type="1">
<li>Smart quotes become regular ASCII quotes.</li>
<li>Special spaces (wide, narrow) become ASCII space.</li>
<li>Soft hyphens and invisible spaces disappear.</li>
<li>Dashes become ASCII hyphen/minus.</li>
<li>Horizontal bar becomes a double-hyphen.</li>
<li>Ellipsis becomes ASCII "..."</li>
<li>The fraction slash becomes regular ASCII slash.</li>
<li>The swung dash becomes ASCII tilde.</li>
<li>Anything else becomes ? and sets the error flag.</li>
</ol>
<p>Note that the resulting string might be longer than the original, so the length must be checked after encoding if there are constraints on the number of characters.</p>
<h1><a class="anchor" id="autotoc_md11"></a>
Japanese via ISO 2022</h1>
<p>The use of iso-2022 escape sequences for the encoding of Japanese text was common before its standardization as iso-2022-jp, and many extensions to iso-2022-jp, both formal and informal, continued to arise until as late as 2004. Our decoder aims to broadly support most of these extensions, while our encoder aims to strictly follow the rules set in the DICOM standard.</p>
<p>DICOM iso-2022 Japanese differs from iso-2022-jp most significantly in the optional inclusion, in DICOM, of ISO IR 13 in G1. This is done to support the use of half-width katakana in the traditional manner as described in JIS X 0201 and as commonly done in Japanese desktop computing and industrial computing.</p>
<p>The Specific Character Set defined term "ISO 2022 IR 13" indicates that the initial state of the decoder will be ISO IR 14 in G0 and ISO IR 13 in G1. Furthermore, the decoder returns to the initial state for every new line of text (that is, after every CRNL).</p>
<p>In this usage, <code>ESC )I</code> will re-designate ISO IR 13 to G1 (though it is not recommended to designate any other character set to G1), and <code>ESC (J</code> will re-designated ISO IR 14 to G0.</p>
<h2><a class="anchor" id="autotoc_md12"></a>
Decoding</h2>
<p>Our decoder includes the following extensions to DICOM's ISO 2022 Japanese:</p>
<ol type="1">
<li>Extra characters from Microsoft CP932.</li>
<li><code>ESC (I</code> will place ISO IR 13 in G0.</li>
<li><code>ESC (H</code> will place ISO IR 14 in G0.</li>
<li><code>ESC $@</code> will place ISO IR 87 in G0.</li>
<li><code>ESC &amp;@ ESC $B</code> will place ISO IR 87 in G0.</li>
<li>All of iso-2022-jp-2 is supported.</li>
</ol>
<p>Notes:</p>
<ol type="1">
<li>When iso-2022-jp text is encoded on Windows, it can contain characters that do not exist in JIS X 0208:1990. This is because the Windows code page for Japanese, CP932, contains these extra characters. The inclusion of these characters in text labelled as "iso-2022-jp" can be either accidental or intentional, as in "iso-2022-jp-ms".</li>
<li>The popular encodings euc-jp, shift-jis, and CP932 contain half-width katakana while iso-2022-jp does not. To allow conversion of these characters to 7-bit iso-2022, the extension 'iso-2022-jp-ext' uses <code>ESC (I</code> to allow half-width katakana in G0.</li>
<li>The use of <code>ESC (H</code> to place ISO IR 14 was a non-standard historical practice. It can occur in very old text.</li>
<li>The <code>ESC $@</code> sequence is for ISO IR 42 (JISC 6226-1978), which predates ISO IR 87 and is a strict subset of ISO IR 87. Support of this escape sequence is required by iso-2022-jp.</li>
<li>With the introduction of JIS X 0212:1990, JIS X 0208:1983 was updated to JIS X 0208:1990 with minor revisions. Rather than register a new iso-ir number for the JIS X 0208:1990, a new compound escape code <code>ESC &amp;@ ESC $B</code> was adopted, though it is rarely used.</li>
<li>Since iso-2022-jp-2 is the most commonly-used extension to iso-2022-jp, supporting it in full seemed apropos.</li>
</ol>
<p>The JIS X 0213 standard and its encodings iso-2022-jp-3 and iso-2022-jp-2004 are not supported. They are rarely used and they conflict with the informal iso-2022-jp-ms extension.</p>
<h2><a class="anchor" id="autotoc_md13"></a>
Encoding</h2>
<p>Encoding of ISO-2022 Japanese in DICOM is usually done with the following defined terms for Specific Character Set:</p>
<ol type="1">
<li>ISO 2022 IR 13\ISO 2022 IR 87</li>
<li>\ISO 2022 IR 87</li>
<li>\ISO 2022 IR 87\ISO 2022 IR 159</li>
</ol>
<p>Notes:</p>
<ol type="1">
<li>This generally implies iso-2022-jp, but requires the use of romaji instead of ASCII, and also requires the use of JIS X 0208:1900 rather than any other version (such as JIS X 0208-1978 or JIS X 0208-1983). This provides exactly the same characters as classic shift-jis, with exactly the same method for encoding romaji and half-width katakana, but with a different way of encoding the JIS X 0208 characters.</li>
<li>This specifies the most widely used subset of iso-2022-jp, using only ASCII and JIS X 0208:1900. For broad compability, this is the best.</li>
<li>This specifies the most widely used subset of iso-2022-jp-2, like the above but adding JIS X 0212:1990 for additional characters.</li>
</ol>
<p>It is preferred to avoid the use of ISO 2022 IR 13 (and ISO IR 13), both because it requires the use of romaji (not ASCII) in G0, and because half-width katakana are not supported by either iso-2022-jp or by iso-2022-jp-2.</p>
<p>For (2) and (3) above, when our encoder encouters half-width katakana, it will convert them to full-width katakana for ISO 2022 IR 87. For (1), or whenever ISO IR 13 is present, the half-width katakana will be encoded as-is.</p>
<p>Regarding the structure of the ISO 2022 encoding, our encoder will always switch G0 to ASCII (or romaji if ISO IR 13) before any ASCII character, including any control character except ESC. This includes SPACE and TAB as well as CR, NL, and FF.</p>
<p>Of course some tricky situations can arise when converting from UTF-8 to ISO 2022 Japanese, or even when converting from Windows CP932, which contains characters not present in JIS X 0208 or JIS X 0212. Firstly, ISO 2022 IR 13 should only be used if half-width katakana are present in the original text and cannot be avoided. Secondly, it is important to note that some characters might be converted to equivalents at different code points in order to make them compatible with either JIS X 0208 or JIS X 0212.</p>
<p>The following characters are considered to be compatible by our encoder, and will be converted if necessary to fit them into an encoding:</p>
<ol type="1">
<li>MACRON and FULLWIDTH MACRON</li>
<li>OVERLINE and FULLWIDTH MACRON</li>
<li>REVERSE SOLIDUS and FULLWIDTH REVERSE SOLIDUS</li>
<li>YEN SIGN and FULLWIDTH YEN SIGN</li>
<li>CENT SIGN and FULLWIDTH CENT SIGN</li>
<li>POUND SIGN and FULLWIDTH POUND SIGN</li>
<li>MINUS SIGN and FULLWIDTH HYPHEN-MINUS</li>
<li>NOT SIGN and FULLWIDTH NOT SIGN</li>
<li>EM DASH and HORIZONTAL BAR</li>
<li>FULLWIDTH TILDE and WAVE DASH</li>
<li>TILDE and FULLWIDTH TILDE</li>
<li>PARALLEL TO and DOUBLE VERTICAL LINE</li>
</ol>
<p>The use of the romaji character set (implied by the ISO IR 2022 13 defined term) causes some specific issues regarding compatibility mapping, since it does not contain tilde or backslash (REVERSE SOLIDUS). So when encoding to ISO 2022 with romaji in G0, tilde is converted to FULLWIDTH TILDE (in JIS X 0212) and backslash is converted to FULLWIDTH REVERSE SOLIDUS (in JIS X 0208). This is done to avoid tilde and backslash from appearing as MACRON and YEN, respectively.</p>
<p>This romaji-specific compatibility mapping is yet another reason to avoid the use of ISO IR 13 unless half-width katakana are absolutely necessary.</p>
<h1><a class="anchor" id="autotoc_md14"></a>
Korean via ISO 2022</h1>
<p>Outside of DICOM, ISO 2022 escape sequences are generally not used in encodings of Korean. In fact, the euc-kr encoding is identical to DICOM's Korean encoding except that it lacks the escape sequences. Conversely, DICOM requires the escape sequence <code>ESC $)C</code> at the beginning of every line of text that contains Korean characters.</p>
<h2><a class="anchor" id="autotoc_md15"></a>
Decoding</h2>
<p>Though required by the DICOM standard, the escape sequences are not present in all Korean DICOM files. Therefore, our decoder will simply remove the escape sequence wherever it is found, and decode the text using Microsoft CP949 (which is backwards compatible with euc-kr, which in turn is identical to DICOM ISO 2022 IR 149 except for the escape sequences). As compared to euc-kr, CP949 contains thousands of additional characters.</p>
<p>As well, KS X 1001 (and ISO IR 149) permit Hangul to be stored using 8-byte codes rather than 2-byte codes. This eight-byte code stores the character using four 2-byte component codes, and was necessary because ISO IR 149 did not contain enough code points for all characters used in Korean. Our decoder will convert each of these 8-byte codes into a single Unicode character.</p>
<h2><a class="anchor" id="autotoc_md16"></a>
Encoding</h2>
<p>Our ISO 2022 IR 149 encoder places the escape <code>ESC $)C</code> sequence at the front of every line that uses Korean characters (or any characters from KS X 1001), as required by DICOM. Hangul that do not exist in KS X 1001 are decomposed and stored as 8-byte codes.</p>
<h1><a class="anchor" id="autotoc_md17"></a>
Chinese via GB18030</h1>
<p>The GB18030 encoding was designed to encompass all Unicode code points. Every GB18030 code point maps to a unique Unicode code point and vice-versa. Since some GB18030 character codes map to the the Private Use Area (PUA) of Unicode, there are some special considerations for the use of GB18030 as discussed below. Also, it must be noted that searching for ASCII backslash (0x5c) in GB18030-encoded strings must be done with care, as some two-byte character codes have 0x5c as the second byte.</p>
<h2><a class="anchor" id="autotoc_md18"></a>
Decoding</h2>
<p>Decoding is done strictly according to the GB18030:2000 mapping tables. A small number of GB18030 characters map to locations in the Unicode PUA region, and will therefore only display correctly when used with a Chinese font that was designed for GB18030 (or for the GBK standard, which GB18030 extends).</p>
<p>The Unicode 4.1 standard of 2005 added official code points for the characters that GB18030 maps to the PUA, so in the absence of fonts that include the correct glyphs at the PUA code points, those PUA code points can be mapped to Unicode 4.1 code points for display. Our decoder does not perform this additional mapping, since this would break round-trip mapping using the official GB18030:2000 tables.</p>
<h2><a class="anchor" id="autotoc_md19"></a>
Encoding</h2>
<p>As with decoding, encoding is done strictly according to the GB18030:2000 tables. Unlike our encoders for other character sets, our GB18030 encoder does not perform any compatibility conversions. This is because every Unicode code point maps to a unique GB18030 code point.</p>
<h1><a class="anchor" id="autotoc_md20"></a>
Chinese via GBK</h1>
<p>The GBK character table is a strict subset of GB18030, and does not encompass all of Unicode. Like GB18030, special consideration is needed for scanning GBK strings for backslash, since the second byte of some two-byte characters might have the value 0x5c.</p>
<h2><a class="anchor" id="autotoc_md21"></a>
Decoding</h2>
<p>The GBK table maps some code points to the Unicode PUA, so the same PUA concerns apply to GBK as apply to GB18030.</p>
<h2><a class="anchor" id="autotoc_md22"></a>
Encoding</h2>
<p>Unlike GB18030, our encoder for GBK includes several compatibility conversions. One conversion (for Unicode 0x1E3F) is related to GB18030:2005, 24 are for characters that were added to Unicode in 2005, and the remainder are to support round-trip mapping for Unicode strings containing PUA code points that were present in older versions of the GBK mapping tables.</p>
<h1><a class="anchor" id="autotoc_md23"></a>
Chinese via ISO 2022</h1>
<p>DICOM's ISO 2022 IR 58 is identical to the popular euc-cn encoding of GB2312, except that DICOM requires the use of <code>ESC $)A</code> at the beginning of every line containing characters from GB2312. Unlike GBK and GB18030, the second byte of a two-byte GB2312 character code will never be 0x5c (ASCII backslash).</p>
<h2><a class="anchor" id="autotoc_md24"></a>
Decoding</h2>
<p>Decoding is done by removing the <code>ESC $)A</code> escape sequence and decoding as GB2312 in its euc-cn form. The table used for decoding is a strict subset of the table defined by GB18030:2000.</p>
<h2><a class="anchor" id="autotoc_md25"></a>
Encoding</h2>
<p>Encoding involves adding the <code>ESC $)A</code> escape sequence at the beginning of every line containing Chinese characters, and also provides the relevant subset of the compatibility conversions that are done for GBK.</p>
<h1><a class="anchor" id="autotoc_md26"></a>
Considerations for UTF-8</h1>
<p>When decoding UTF-8 data, there are a small number of important concerns. Foremost, the UTF-8 sequences must be checked for validity, and each sequence must decode to a code point between 0x00000 and 0x10FFFF. UTF-16 surrogate code points must be detected (0xD800 to 0xDFFF), since these are also invalid in UTF-8. Finally, any codes in the Private Use Area (PUA, 0xE000â€“0xF8FF) might need special consideration.</p>
<p>Our UTF-8 decoder simply re-encodes as UTF-8 after examining the string. That is, the decoder and the encoder are one and the same, and its only purpose is to check for invalid UTF-8 byte sequences and invalid Unicode code points. The PUA code points are simply passed through, as are any unassigned code points. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Sun Jun 26 2022 23:29:08 for vtk-dicom by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.17
</small></address>
</body>
</html>
